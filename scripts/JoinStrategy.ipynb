{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1373ad4-0382-415f-b731-678b1b06d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f3c841ac100>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2778c99-4749-49a3-8cfc-4fec1274ab27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Default Strategy\n",
    "    1. Broadcast Join (If one table is small)\n",
    "    2. Sort-Merge Join (If no broadcast is possible)\n",
    "    3. Shuffle Hash Join (If explicitly enabled -> spark.sql.join.preferSortMergeJoin=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff79d8-745d-44f0-a1fe-5e6ea406e367",
   "metadata": {},
   "source": [
    "## Broadcast Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6595398-10e6-4e88-b2a4-ab398fae798a",
   "metadata": {},
   "source": [
    "#### When used:\n",
    "    - One table is small enough to fit in memory (usually < 10 MB by default, but configurable)\n",
    "    - Spark broadcasts the small datasets to all executors\n",
    "#### How it works:\n",
    "    - The small table is replicated to each worker node.\n",
    "    - Each worker scans its partition of the large table and performs a hash join with small one\n",
    "#### Best for : Large Table + Small Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f44c40f-ed76-44fa-910e-0a8c6f46bc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10) # Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4cc8dc-9873-4f6a-9c50-9fd10ef21a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1) # Disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e404c9-67ae-4809-bfe3-51392d9e4e65",
   "metadata": {},
   "source": [
    "## Shuffle Hash Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f669f2-fc30-430a-beef-2a800c65e908",
   "metadata": {},
   "source": [
    "#### When used:\n",
    "    - Both datasets are large and no broadcast is possible\n",
    "    - At least one datasets can fit in memory after shuffling by the join key\n",
    "#### How it works:\n",
    "    - Both tables are shuffled on join keys so that matching keys end up in the same partition\n",
    "    - Each partition builds a hash table of one side and probes with the other\n",
    "#### Best for: Medium-size datatsets with good hash distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b2678b-38af-4984-a55d-0aad5b575980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.join.preferSortMergeJoin\", \"false\")\n",
    "spark.conf.set(\"spark.sql.join.forceApplyShuffleHashJoin\", \"true\") # Enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b9a09bd-22f2-4555-9b05-4e96f6ca7869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.join.forceApplyShuffledHashJoin\", \"false\") # Disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f9ea5-e574-468b-aade-b5faf6c8c36d",
   "metadata": {},
   "source": [
    "## Sort Merge Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47e6d0-9dfe-44a8-a488-862325cbbfb2",
   "metadata": {},
   "source": [
    "#### When used:\n",
    "    - Default strategy when tables are large and not broadcastable\n",
    "    - Works well when inputs are already sorted (e.g., from shuffle)\n",
    "#### How it works:\n",
    "    - Both tables are shuffled on join keys\n",
    "    - Data in each partition is sorted, then merged like in merge-sort\n",
    "#### Best for: Very large tables, especially when join keys are well distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc2ffa1-eb87-4788-ac4c-08ea0edfd827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.join.preferSortMergeJoin\", \"true\") # Enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a80e712-3c8a-4d0c-b068-a9636af7f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.join.preferSortMergeJoin\", \"false\") # Disable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574e5a7-1628-4f66-81c7-097fa25410c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
