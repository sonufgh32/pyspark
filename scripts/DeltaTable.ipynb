{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e2954-6bdc-4bd1-910c-1db1bb349646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark \\\n",
    "#   --packages io.delta:delta-core_2.12:2.3.0 \\\n",
    "#   --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" \\\n",
    "#   --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0ad38a-9c8d-4b0f-ae58-4a68e1559fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "No module named 'delta'\n",
      "Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'delta'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d9cece-a1dc-4c05-9bcc-2900d4af9fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", 30, \"2025-12-01\"),\n",
    "    (2, \"Bob\",   28, \"2025-12-01\"),\n",
    "    (3, \"Cleo\",  35, \"2025-12-02\"),\n",
    "]\n",
    "cols = [\"id\", \"name\", \"age\", \"dt\"]\n",
    "\n",
    "df = spark.createDataFrame(data, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8177f6-e042-498c-80d6-fd6cbea74ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o85.saveAsTable.\n",
      ": java.lang.ClassNotFoundException: \n",
      "Failed to find data source: delta. Please find packages at\n",
      "https://spark.apache.org/third-party-projects.html\n",
      "       \n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:574)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:675)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:725)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:864)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:562)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.ClassNotFoundException: delta.DefaultSource\n",
      "\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:661)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:661)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:661)\n",
      "\t... 14 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/glue_user/spark/python/pyspark/sql/readwriter.py\", line 1041, in saveAsTable\n",
      "    self._jwrite.saveAsTable(name)\n",
      "  File \"/home/glue_user/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/glue_user/spark/python/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/glue_user/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o85.saveAsTable.\n",
      ": java.lang.ClassNotFoundException: \n",
      "Failed to find data source: delta. Please find packages at\n",
      "https://spark.apache.org/third-party-projects.html\n",
      "       \n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedToFindDataSourceError(QueryExecutionErrors.scala:574)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:675)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:725)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:864)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:562)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.ClassNotFoundException: delta.DefaultSource\n",
      "\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:661)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:661)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:661)\n",
      "\t... 14 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").partitionBy(\"dt\").saveAsTable(\"my_glue_db.delta_exp_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1fc44d-e5df-4aad-ac2c-034e8c045044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_df = spark.createDataFrame([\n",
    "    (1, \"Alice\", 30),\n",
    "    (2, \"Bob\", 28),\n",
    "    (4, \"Dave\", 35)\n",
    "], [\"id\",\"name\",\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35519f7e-d95b-48f9-9e1d-1f099a4eebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"my_glue_db.delta_src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a4d1c-9da8-4ecd-9abd-3609d0e06781",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DeltaTable.isDeltaTable(spark, spark.sql(\"DESCRIBE DETAIL my_glue_db.delta_src\").collect()[0]['location']):\n",
    "    target_initial = spark.createDataFrame([\n",
    "        (1, \"Alice\", 29),   # age changed\n",
    "        (2, \"Bob\", 28),\n",
    "        (3, \"Charlie\", 40)\n",
    "    ], [\"id\",\"name\",\"age\"])\n",
    "    target_initial.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"my_glue_db.delta_src_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256bc4d-ec79-48c0-9a4c-bc194c48ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table = DeltaTable.forPath(spark, spark.sql(\"DESCRIBE DETAIL my_glue_db.delta_src\").collect()[0]['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981cb93e-313e-4822-b7df-b583acda5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table.alias(\"t\").merge(source_df.alias(\"s\"), \"t.id = s.id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c80f2-2753-4fce-94e2-cba5fb680344",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from my_glue_db.delta_src\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa1938-6f8e-4a10-8f73-3158a94e63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_source_df = spark.createDataFrame([\n",
    "    (1, \"Alice\", 50),\n",
    "    (2, \"Bob\", 15),\n",
    "    (5, \"Rey\", 25),\n",
    "    (7, \"Rashi\", 30)\n",
    "], [\"id\",\"name\",\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db7c4e-3ced-4ebc-b3cf-56eda3d3e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table.alias(\"t\").merge(new_source_df.alias(\"s\"), \"t.id = s.id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b395f-73ce-46b3-b63d-a2f40f524afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from my_glue_db.delta_src\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afd6860-173a-4e90-a8bb-9ef218a02215",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "name 'delta_table' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'delta_table' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_table.delete(\"true\") # deletes all data files but keeps metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15f644-11fd-46f8-8913-cb4eaae9a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS my_glue_db.delta_src\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS my_glue_db.delta_exp_tbl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
